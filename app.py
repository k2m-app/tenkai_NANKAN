import streamlit as st
import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
import time
import re
import traceback
import unicodedata

# ==========================================
# 0. ãƒ­ã‚°ã‚¤ãƒ³ï¼†ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
# ==========================================

def login_keibabook(user_id, password):
    """ ç«¶é¦¬ãƒ–ãƒƒã‚¯ã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’è¿”ã™ """
    session = requests.Session()
    session.headers.update({"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"})
    
    login_page_url = "https://s.keibabook.co.jp/login/login"
    
    try:
        # 1. ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦CSRFãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
        res = session.get(login_page_url)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        csrf_token = ""
        meta_csrf = soup.find('meta', {'name': 'csrf-token'})
        if meta_csrf:
            csrf_token = meta_csrf['content']
            
        # 2. ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ã‚’POST
        payload = {
            '_token': csrf_token,
            'login_id': user_id, 
            'password': password
        }
        
        post_res = session.post(login_page_url, data=payload)
        
        # ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸåˆ¤å®š
        if "ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ" in post_res.text or "ãƒã‚¤ãƒšãƒ¼ã‚¸" in post_res.text:
            return session, True, "ãƒ­ã‚°ã‚¤ãƒ³ã«æˆåŠŸã—ã¾ã—ãŸã€‚"
        else:
            return session, False, "ãƒ­ã‚°ã‚¤ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸã€‚IDã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            
    except Exception as e:
        return None, False, f"ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

# ==========================================
# 1. ãƒšãƒ¼ã‚¹è§£æãƒ»å±•é–‹äºˆæƒ³ã®ã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯ (å—é–¢ç‰¹åŒ–ç‰ˆ)
# ==========================================

NANKAN_TRACK_BIAS = {
    "å¤§äº•": 0.5,   
    "èˆ¹æ©‹": 0.0,   
    "å·å´": -0.1,  
    "æµ¦å’Œ": -0.3   
}

def calculate_early_pace_speed(row, current_dist):
    if pd.isna(row.get('early_3f')):
        return np.nan
        
    normalized_3f = row['early_3f']
    past_venue = row.get('venue', '')
    
    if past_venue in NANKAN_TRACK_BIAS:
        normalized_3f -= NANKAN_TRACK_BIAS[past_venue]
    elif past_venue not in ["æ±äº¬", "ä¸­å±±", "äº¬éƒ½", "é˜ªç¥", "ä¸­äº¬", "æ–°æ½Ÿ", "ç¦å³¶", "å°å€‰", "æœ­å¹Œ", "å‡½é¤¨"]:
        normalized_3f += 0.3 
    
    raw_speed = 600.0 / normalized_3f

    condition_mod = 0.0
    if row['track_condition'] in ["é‡", "ä¸è‰¯"]: condition_mod = -0.15 
    elif row['track_condition'] == "ç¨": condition_mod = -0.05

    dist_diff = row['distance'] - current_dist
    distance_mod = 0.0
    if dist_diff > 0:
        distance_mod = -(dist_diff / 100.0) * 0.05
    elif dist_diff < 0:
        distance_mod = -(abs(dist_diff) / 100.0) * 0.10

    return raw_speed + condition_mod + distance_mod

def determine_running_style(past_df: pd.DataFrame) -> str:
    if past_df.empty: return "ä¸æ˜"
    is_good_run = (past_df['finish_position'] <= 4)
    good_runs = past_df[is_good_run]
    
    if good_runs.empty: return "ä¸æ˜"
    good_positions = good_runs['first_corner_pos'].tolist()
    
    if all(pos == 1 for pos in good_positions): return "ãƒãƒŠçµ¶å¯¾"
    if any(2 <= pos <= 5 for pos in good_positions): return "æ§ãˆOK"
    return "å·®ã—è¿½è¾¼"

def calculate_pace_score(horse, current_dist, current_venue, current_track, total_horses):
    past_df = pd.DataFrame(horse['past_races'])
    
    if past_df.empty: 
        horse['score'] = 10.0 + ((horse['horse_number'] - 1) * 0.05)
        horse['special_flag'] = "â“ãƒ‡ãƒ¼ã‚¿ä¸è¶³"
        horse['running_style'] = "ä¸æ˜"
        return horse['score']
    
    horse['running_style'] = determine_running_style(past_df)
    past_df['early_speed'] = past_df.apply(lambda row: calculate_early_pace_speed(row, current_dist), axis=1)
    max_speed = past_df['early_speed'].max()
    horse['max_early_speed'] = max_speed if not pd.isna(max_speed) else 16.0
    
    speed_advantage = 0.0
    if not pd.isna(max_speed):
        speed_advantage = (16.8 - max_speed) * 4.0 

    jockey_target = float(past_df.iloc[0]['first_corner_pos']) if not past_df.empty else 7.0
    base_position = (jockey_target * 0.6) + speed_advantage
    
    base_mod = (horse['horse_number'] - 1) * 0.05 
    horse['special_flag'] = ""
    late_start_penalty = 0.0
    
    if current_venue in ["æµ¦å’Œ", "å·å´"]:
        if horse['running_style'] == "å·®ã—è¿½è¾¼":
            base_mod += 1.5
            horse['special_flag'] = "âš ï¸å°å›ã‚Šå·®ã—å³é‡æ³¨æ„"
        
        if horse['horse_number'] <= 4:
            base_mod -= 0.5
        elif horse['horse_number'] >= 10:
            base_mod += 0.8
            horse['special_flag'] = (horse['special_flag'] + " ğŸ“‰å¤–æ ä¸åˆ©").strip()
            
    elif current_venue == "å¤§äº•":
        if horse['running_style'] == "å·®ã—è¿½è¾¼":
            base_mod -= 0.5
            horse['special_flag'] = "âœ¨å¤§äº•å·®ã—è­¦æˆ’"

    last_race = past_df.iloc[0]
    weight_diff = horse['current_weight'] - last_race['weight']
    weight_modifier = weight_diff * 0.25
    
    is_outer_5 = horse['horse_number'] > (total_horses - 5)
    if is_outer_5 and weight_diff > -2.0 and horse['running_style'] != "ãƒãƒŠçµ¶å¯¾" and current_venue != "å¤§äº•":
        late_start_penalty += 0.7 
        horse['special_flag'] = (horse['special_flag'] + " ğŸ‘ï¸å¤–æ æ§˜å­è¦‹").strip()

    final_score = base_position + weight_modifier + base_mod + late_start_penalty
    return max(1.0, min(18.0, final_score))

def format_formation(sorted_horses):
    if not sorted_horses: return ""
    leaders, chasers, mid, backs = [], [], [], []
    top_score = sorted_horses[0]['score']
    for h in sorted_horses:
        num_str = chr(9311 + h['horse_number']) 
        score = h['score']
        if score <= top_score + 1.2 and len(leaders) < 3: leaders.append(num_str)
        elif score <= top_score + 4.5: chasers.append(num_str)
        elif score <= top_score + 9.5: mid.append(num_str)
        else: backs.append(num_str)
    
    parts = []
    if leaders: parts.append(f"({''.join(leaders)})")
    if chasers: parts.append("".join(chasers))
    if mid: parts.append("".join(mid))
    if backs: parts.append("".join(backs))
    return " ".join(parts)

# ==========================================
# 2. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å¯¾å¿œç‰ˆï¼‰
# ==========================================

def extract_corner_pos(text):
    text = text.strip()
    match = re.search(r'\d+', text)
    if match: return int(match.group())
    for char in text:
        try:
            if 'CIRCLED' in unicodedata.name(char): return int(unicodedata.numeric(char))
        except: pass
    return 7

def fetch_horse_details(session, horse_url, current_dist):
    try:
        response = session.get(horse_url)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')
        past_races = []
        
        history_divs = soup.select('div.uma_seiseki')
        for div in history_divs:
            if len(past_races) >= 5: break
                
            negahi_span = div.select_one('.negahi')
            if not negahi_span: continue
            date_venue = negahi_span.text.replace('\xa0', ' ').strip()
            parts = re.split(r'\s+', date_venue)
            p_venue = parts[-1] if len(parts) > 1 else "ä¸æ˜"
            
            kyori_span = div.select_one('.kyori')
            dist = current_dist
            baba_cond = "è‰¯"
            if kyori_span:
                k_text = kyori_span.text
                d_match = re.search(r'\d+', k_text)
                if d_match: dist = int(d_match.group())
                if "ä¸è‰¯" in k_text: baba_cond = "ä¸è‰¯"
                elif "é‡" in k_text: baba_cond = "é‡"
                elif "ç¨" in k_text: baba_cond = "ç¨"
                
            finish_pos = 5
            cyakujun_span = div.select_one('.cyakujun')
            if cyakujun_span:
                f_match = re.search(r'\d+', cyakujun_span.text)
                if f_match: finish_pos = int(f_match.group())
                
            early_3f = np.nan
            agari_span = div.select_one('.agari')
            if agari_span:
                agari_text = agari_span.text.strip()
                matches = re.findall(r'(\d+\.\d+)', agari_text)
                if matches: early_3f = float(matches[0]) 
                    
            first_corner = 7
            tuka_lis = div.select('.tuka li span')
            if tuka_lis: first_corner = extract_corner_pos(tuka_lis[0].text)
                
            weight = 480.0
            batai_span = div.select_one('.batai')
            if batai_span:
                w_match = re.search(r'(\d+)', batai_span.text)
                if w_match: weight = float(w_match.group())
                
            past_races.append({
                'venue': p_venue, 'track_type': "ãƒ€ãƒ¼ãƒˆ", 'distance': dist,
                'track_condition': baba_cond, 'finish_position': finish_pos,
                'popularity': 5, 'early_3f': early_3f,
                'first_corner_pos': first_corner, 'is_late_start': False,
                'past_frame': 4, 'weight': weight
            })
            
        return past_races
    except Exception as e:
        return []

@st.cache_data(ttl=600, show_spinner=False)
def fetch_real_data(_session, target_race_id: str):
    race_url = f"https://s.keibabook.co.jp/chihou/syutuba/{target_race_id}"
    try:
        response = _session.get(race_url)
        response.encoding = 'utf-8' 
        soup = BeautifulSoup(response.text, 'html.parser')
        
        racemei_elem = soup.select_one('.racemei p')
        current_venue = racemei_elem.text.strip() if racemei_elem else "ä¸æ˜"
        if current_venue == "ä¸æ˜": return None, 1400, "", "ãƒ€ãƒ¼ãƒˆ", "å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
        
        sub_info = soup.select('.racetitle_sub p')
        dist_text = ""
        for p in sub_info:
            if "m" in p.text:
                dist_text = p.text
                break
                
        current_dist = int(re.search(r'\d+', dist_text).group()) if dist_text else 1400
        current_track = "ãƒ€ãƒ¼ãƒˆ"

        horses_data = []
        rows = soup.select('table.syutuba_sp tbody tr')
        if not rows: return None, current_dist, current_venue, current_track, "å‡ºèµ°é¦¬ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"

        progress_bar = st.progress(0)
        total_rows = len(rows)

        for i, row in enumerate(rows):
            umaban_td = row.select_one('td[class^="waku"]')
            if not umaban_td: continue
            horse_num = int(umaban_td.text.strip())
            
            bamei_a = row.select_one('.kbamei a')
            if not bamei_a: continue
            horse_name = bamei_a.text.strip()
            horse_url = "https://s.keibabook.co.jp" + bamei_a['href']
            
            past_races = fetch_horse_details(_session, horse_url, current_dist)
            current_weight = past_races[0]['weight'] if past_races else 480.0
            
            horses_data.append({
                'horse_number': horse_num, 'horse_name': horse_name,
                'current_weight': current_weight, 'past_races': past_races,
                'score': 0.0, 'special_flag': ""
            })
            
            time.sleep(0.5) 
            progress_bar.progress((i + 1) / total_rows)
            
        progress_bar.empty()
        if not horses_data: return None, 1400, "", "ãƒ€ãƒ¼ãƒˆ", "é¦¬ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        return horses_data, current_dist, current_venue, current_track, None
        
    except Exception as e:
        return None, 1400, "", "ãƒ€ãƒ¼ãƒˆ", f"ã‚¨ãƒ©ãƒ¼: {e}"

# ==========================================
# 3. ã‚¹ãƒãƒ›å¯¾å¿œUI & Secretsãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†
# ==========================================
st.set_page_config(page_title="AIå—é–¢å±•é–‹äºˆæƒ³", page_icon="ğŸ‡", layout="centered")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–
if 'kb_session' not in st.session_state:
    st.session_state.kb_session = requests.Session()
if 'is_logged_in' not in st.session_state:
    st.session_state.is_logged_in = False

# Secretsã‹ã‚‰æƒ…å ±ã‚’å–å¾—ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼‰
try:
    secret_id = st.secrets["keibabook"]["login_id"]
    secret_pw = st.secrets["keibabook"]["password"]
    has_secrets = True
except (KeyError, FileNotFoundError):
    has_secrets = False

with st.sidebar:
    st.header("ğŸ”‘ ç«¶é¦¬ãƒ–ãƒƒã‚¯ ãƒ­ã‚°ã‚¤ãƒ³")
    
    if not st.session_state.is_logged_in:
        if has_secrets:
            # Secretsã«æƒ…å ±ãŒã‚ã‚Œã°ãƒœã‚¿ãƒ³ä¸€ã¤ã§ãƒ­ã‚°ã‚¤ãƒ³
            st.info("Secretsã«èªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚")
            if st.button("ğŸ”’ è‡ªå‹•ãƒ­ã‚°ã‚¤ãƒ³å®Ÿè¡Œ", type="primary"):
                with st.spinner("ãƒ­ã‚°ã‚¤ãƒ³ä¸­..."):
                    session, success, msg = login_keibabook(secret_id, secret_pw)
                    if success:
                        st.session_state.kb_session = session
                        st.session_state.is_logged_in = True
                        st.success(msg)
                        st.rerun()
                    else:
                        st.error(msg)
        else:
            # SecretsãŒãªã„å ´åˆã¯æ‰‹å‹•å…¥åŠ›ã‚’ä¿ƒã™ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            st.warning("SecretsãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚æ‰‹å‹•ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            kb_id = st.text_input("ãƒ­ã‚°ã‚¤ãƒ³ID (ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ç­‰)")
            kb_pw = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
            if st.button("ãƒ­ã‚°ã‚¤ãƒ³å®Ÿè¡Œ"):
                with st.spinner("ãƒ­ã‚°ã‚¤ãƒ³ä¸­..."):
                    session, success, msg = login_keibabook(kb_id, kb_pw)
                    if success:
                        st.session_state.kb_session = session
                        st.session_state.is_logged_in = True
                        st.success(msg)
                        st.rerun()
                    else:
                        st.error(msg)
    else:
        st.success("ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿ã§ã™ âœ…")
        if st.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ"):
            st.session_state.kb_session = requests.Session()
            st.session_state.is_logged_in = False
            st.rerun()

st.title("ğŸ‡ AIç«¶é¦¬å±•é–‹äºˆæƒ³ (å—é–¢ç‰¹åŒ–ç‰ˆ)")
st.markdown("å¤§äº•ã®ç™½ç ‚è£œæ­£ã‚„ã€æµ¦å’Œãƒ»å·å´ã®å¼·ã„å‰æ®‹ã‚Šãƒã‚¤ã‚¢ã‚¹ã‚’åŠ å‘³ã—ãŸéšŠåˆ—äºˆæƒ³ã‚’è¡Œã„ã¾ã™ã€‚â€»ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ãŸã‚ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã®ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ã§ã™ã€‚")

with st.container(border=True):
    st.subheader("âš™ï¸ ãƒ¬ãƒ¼ã‚¹è¨­å®š")
    base_url_input = st.text_input("ğŸ”— åœ°æ–¹ç«¶é¦¬å‡ºé¦¬è¡¨URLã‚’è²¼ã‚Šä»˜ã‘", value="https://s.keibabook.co.jp/chihou/syutuba/2026021301010223")
    
    try:
        selected_races = st.pills("ãƒ¬ãƒ¼ã‚¹ç•ªå·", options=list(range(1, 13)), default=[1], format_func=lambda x: f"{x}R", selection_mode="multi")
    except AttributeError:
        selected_races = st.multiselect("ãƒ¬ãƒ¼ã‚¹ç•ªå·", options=list(range(1, 13)), default=[1], format_func=lambda x: f"{x}R")

    if not isinstance(selected_races, list):
        selected_races = [selected_races] if selected_races else []

    col1, col2 = st.columns(2)
    with col1:
        execute_btn = st.button("ğŸš€ é¸æŠãƒ¬ãƒ¼ã‚¹ã‚’äºˆæƒ³", type="primary", use_container_width=True, disabled=not st.session_state.is_logged_in)
    with col2:
        execute_all_btn = st.button("ğŸŒŸ å…¨12Rã‚’ä¸€æ‹¬äºˆæƒ³", type="secondary", use_container_width=True, disabled=not st.session_state.is_logged_in)
        
    if not st.session_state.is_logged_in:
        st.error("âš ï¸ å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ç«¶é¦¬ãƒ–ãƒƒã‚¯ã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚")

run_inference = False
target_races = []
url_prefix = ""
url_suffix = ""

match = re.search(r'(\d{10})(\d{2})(\d{4})', base_url_input)
if match:
    url_prefix = match.group(1)
    url_suffix = match.group(3)

if execute_all_btn:
    run_inference = True
    target_races = list(range(1, 13))
elif execute_btn:
    if not selected_races:
        st.warning("ãƒ¬ãƒ¼ã‚¹ç•ªå·ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    else:
        run_inference = True
        target_races = selected_races

if run_inference:
    if not match:
        st.error("æœ‰åŠ¹ãªç«¶é¦¬ãƒ–ãƒƒã‚¯åœ°æ–¹ç«¶é¦¬ã®ãƒ¬ãƒ¼ã‚¹URLãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    else:
        for race_num in sorted(target_races):
            target_race_id = f"{url_prefix}{race_num:02d}{url_suffix}"
            st.markdown(f"### ğŸ {race_num}R")
            
            with st.spinner(f"{race_num}R ã®å„é¦¬ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’è§£æä¸­..."):
                horses, current_dist, current_venue, current_track, error_msg = fetch_real_data(st.session_state.kb_session, target_race_id)
                
                if error_msg:
                    st.warning(f"{error_msg}")
                    continue
                    
                total_horses = len(horses)
                for horse in horses:
                    horse['score'] = calculate_pace_score(horse, current_dist, current_venue, current_track, total_horses)
                    
                sorted_horses = sorted(horses, key=lambda x: x['score'])
                formation_text = format_formation(sorted_horses)

            st.info(f"ğŸ“ æ¡ä»¶: **{current_venue} {current_track}{current_dist}m** ({total_horses}é ­ç«‹ã¦)")
            st.markdown(f"<h4 style='text-align: center; letter-spacing: 2px;'>â—€(é€²è¡Œæ–¹å‘)</h4>", unsafe_allow_html=True)
            st.markdown(f"<h3 style='text-align: center; color: #FF4B4B;'>{formation_text}</h3>", unsafe_allow_html=True)
            st.markdown("---")
            
            with st.expander(f"ğŸ“Š {race_num}R ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ã‚‹"):
                df_result = pd.DataFrame([{
                    "é¦¬ç•ª": h['horse_number'],
                    "é¦¬å": h['horse_name'],
                    "ã‚¹ã‚³ã‚¢": round(h['score'], 2),
                    "æˆ¦æ³•": h.get('running_style', ''),
                    "ç‰¹è¨˜äº‹é …": h.get('special_flag', '')
                } for h in sorted_horses])
                st.dataframe(df_result, use_container_width=True, hide_index=True)
            st.markdown("<br>", unsafe_allow_html=True)
